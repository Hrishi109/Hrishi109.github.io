---
layout: page
title: Research Proposals
subtitle: Few of the Research Problems I am currently interested in
---


* **Transparent Reinforcement Learning:** Deep Reinforcement Learning(RL) is a powerful technique to train agents to carry out specific tasks. But we still do not know why an agent takes a bad action due to the non-interpretability of deep neural networks. Some recent works have been carried out on making RL agents' actions interpretable like [Object Sensitive Deep Reinforcement Learning by Li et al.](https://arxiv.org/abs/1809.06064). 

* **Imitation Learning with Observations:** In Imitation Learning, we need to give state, action pairs of an expert's demonstration. But in imitation learning in human beings, we do not get the action values while learning. Some of the recent works have been carried out by Liu et al. on [Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation](https://arxiv.org/pdf/1707.03374.pdf). A few of the improvements on this work could be to use 


* **Reinforcement Learning for Block Sparsity Pruning in Deep Neural Networks for Model Compression:**
AutoMl has been used for model compression to get smaller and faster deep neural networks by He et al[[1]](https://arxiv.org/pdf/1802.03494.pdf). But in this work they prune the weights with a reinforcement learning agent layer wise. But one of the better ways to achieve faster networks is by having block sparse weights. A reinforcement learning agent can be used to get block sparse weights.


