---
layout: archive
title: "Paper Summaries"
permalink: /paper_summaries/
author_profile: true
redirect_from:
  - /extracurricular-activities
---

## One-page Summaries of Research Papers I Found Interesting, Along with Potential Extension Ideas

#### Why Write Paper Summaries?
- **Enhanced Retention**: Writing summaries deepens understanding by encouraging critical analysis.
- **Idea Generation**: Helps explore potential extensions by connecting insights from multiple papers.
- **Inspiration to Read More**: The process itself motivates continued learning and exploration.

---

### Summaries and Reviews

| **Paper**       | **Authors**        | **Conference** | **Affiliation**                          | **Summary Link** |
|------------------|--------------------|----------------|-------------------------------------------|------------------|
| [Object Sensitive Deep Reinforcement Learning](https://arxiv.org/abs/1809.06064) | Y. Li, K. Sycara, R. Iyer | GCAI-17 | Carnegie Mellon University | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/Object%20Sensitive%20Deep%20RL/Review.pdf) |
| [Safe Reinforcement Learning with Model Uncertainty Estimates](https://arxiv.org/abs/1810.08700) | B. Lutjens, M. Everett, J. How | ICRA-18 | Massachusetts Institute of Technology | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/Safe%20RL%20with%20model%20uncertainty%20estimates/Safe_RL_review.pdf) |
| [Multi-stage Reinforcement Learning for Object Detection](https://arxiv.org/pdf/1810.10325.pdf) | J. KÃ¶nig et al. | CVC-19 | Paderborn University | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/Multi-Stage%20RL%20for%20Object%20Detection/Multi_Stage_RL_for_Object_Detection_review.pdf) |
| [Curiosity-driven Exploration by Self-supervised Prediction](https://arxiv.org/pdf/1705.05363.pdf) | D. Pathak et al. | ICML-17 | UC Berkeley | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/No%20Reward%20RL/NoRewardRL_review.pdf) |
| [AMC: AutoML for Model Compression and Acceleration on Mobile Devices](https://arxiv.org/pdf/1802.03494.pdf) | Y. He et al. | ECCV-18 | MIT, Carnegie Mellon University | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/AutoML%20for%20Model%20Compression/AutoML_for_Model_Compression_review.pdf) |
| [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf) | V. Mnih et al. | ICML-16 | Google DeepMind, MILA | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/A3C/A3C_review.pdf) |
| [Robust Adversarial Reinforcement Learning](https://arxiv.org/pdf/1703.02702.pdf) | L. Pinto et al. | ICML-17 | Carnegie Mellon University, Google Brain | [Review](https://github.com/Hrishi109/RL-Paper-Reviews/blob/master/Paper%20Summaries/RARL/RARL_summary.pdf) |

---

#### Disclaimer:
The ideas and extensions mentioned in these reviews are my personal thoughts inspired by the papers. They are intended to foster creativity and critical thinking. There is no intent to undervalue or criticize the authors' contributions.

